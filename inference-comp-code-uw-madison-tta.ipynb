{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8eae8e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T22:45:01.482594Z",
     "iopub.status.busy": "2022-07-13T22:45:01.482144Z",
     "iopub.status.idle": "2022-07-13T22:45:49.383665Z",
     "shell.execute_reply": "2022-07-13T22:45:49.382205Z",
     "shell.execute_reply.started": "2022-07-13T22:45:01.482508Z"
    },
    "papermill": {
     "duration": 0.013561,
     "end_time": "2022-07-22T17:23:10.396343",
     "exception": false,
     "start_time": "2022-07-22T17:23:10.382782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Install librairies offline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed01562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:23:10.423383Z",
     "iopub.status.busy": "2022-07-22T17:23:10.422634Z",
     "iopub.status.idle": "2022-07-22T17:23:23.170920Z",
     "shell.execute_reply": "2022-07-22T17:23:23.169399Z"
    },
    "papermill": {
     "duration": 12.765242,
     "end_time": "2022-07-22T17:23:23.174558",
     "exception": false,
     "start_time": "2022-07-22T17:23:10.409316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('./segmentation_models_pytorch')\n",
    "!cp -r ../input/segmentation-models-pytorch/SegmentPModels/* ./segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212df1f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:23:24.228343Z",
     "iopub.status.busy": "2022-07-22T17:23:24.227905Z",
     "iopub.status.idle": "2022-07-22T17:25:28.875776Z",
     "shell.execute_reply": "2022-07-22T17:25:28.874413Z"
    },
    "papermill": {
     "duration": 125.646601,
     "end_time": "2022-07-22T17:25:28.878750",
     "exception": false,
     "start_time": "2022-07-22T17:23:23.232149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q ./segmentation_models_pytorch/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4\n",
    "!pip install -q ./segmentation_models_pytorch/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3\n",
    "!pip install -q ./segmentation_models_pytorch/timm-0.4.12-py3-none-any.whl\n",
    "!pip install -q ./segmentation_models_pytorch/segmentation_models_pytorch-0.2.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd703dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:28.906083Z",
     "iopub.status.busy": "2022-07-22T17:25:28.905511Z",
     "iopub.status.idle": "2022-07-22T17:25:38.500148Z",
     "shell.execute_reply": "2022-07-22T17:25:38.498920Z"
    },
    "papermill": {
     "duration": 9.611024,
     "end_time": "2022-07-22T17:25:38.502839",
     "exception": false,
     "start_time": "2022-07-22T17:25:28.891815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --no-index --find-links=\"../input/highresnet/highresnet\" highresnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f2fa1a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:38.529554Z",
     "iopub.status.busy": "2022-07-22T17:25:38.529253Z",
     "iopub.status.idle": "2022-07-22T17:25:48.909087Z",
     "shell.execute_reply": "2022-07-22T17:25:48.907490Z"
    },
    "papermill": {
     "duration": 10.396404,
     "end_time": "2022-07-22T17:25:48.911745",
     "exception": false,
     "start_time": "2022-07-22T17:25:38.515341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --no-index --find-links=\"../input/torhio/TorchIO\" torchio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a5b49",
   "metadata": {
    "papermill": {
     "duration": 0.012343,
     "end_time": "2022-07-22T17:25:48.937525",
     "exception": false,
     "start_time": "2022-07-22T17:25:48.925182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Import librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661fef13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:48.962958Z",
     "iopub.status.busy": "2022-07-22T17:25:48.962595Z",
     "iopub.status.idle": "2022-07-22T17:25:55.485009Z",
     "shell.execute_reply": "2022-07-22T17:25:55.483926Z"
    },
    "papermill": {
     "duration": 6.538148,
     "end_time": "2022-07-22T17:25:55.487718",
     "exception": false,
     "start_time": "2022-07-22T17:25:48.949570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torchio as tio\n",
    "import torch\n",
    "import torchmetrics \n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "from highresnet import HighRes3DNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import nibabel as nib\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de514a2",
   "metadata": {
    "papermill": {
     "duration": 0.011785,
     "end_time": "2022-07-22T17:25:55.511826",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.500041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecb2e751",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.537417Z",
     "iopub.status.busy": "2022-07-22T17:25:55.536819Z",
     "iopub.status.idle": "2022-07-22T17:25:55.541640Z",
     "shell.execute_reply": "2022-07-22T17:25:55.540648Z"
    },
    "papermill": {
     "duration": 0.019517,
     "end_time": "2022-07-22T17:25:55.543489",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.523972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "debug = False # set debug=False for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3554d9cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.570756Z",
     "iopub.status.busy": "2022-07-22T17:25:55.569908Z",
     "iopub.status.idle": "2022-07-22T17:25:55.575772Z",
     "shell.execute_reply": "2022-07-22T17:25:55.574791Z"
    },
    "papermill": {
     "duration": 0.022486,
     "end_time": "2022-07-22T17:25:55.577864",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.555378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if debug : \n",
    "    ROOT_DIR = '../input/uw-madison-gi-tract-image-segmentation/train'\n",
    "else: \n",
    "    ROOT_DIR ='../input/uw-madison-gi-tract-image-segmentation/test'\n",
    "    #ROOT_DIR = '../input/test-eg-for-inference-mri-madison'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "786a0266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.603441Z",
     "iopub.status.busy": "2022-07-22T17:25:55.602719Z",
     "iopub.status.idle": "2022-07-22T17:25:55.619157Z",
     "shell.execute_reply": "2022-07-22T17:25:55.618225Z"
    },
    "papermill": {
     "duration": 0.031409,
     "end_time": "2022-07-22T17:25:55.621288",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.589879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if debug: \n",
    "    df_original = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\n",
    "else:\n",
    "    df_original = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n",
    "    #df_original = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd051fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.647309Z",
     "iopub.status.busy": "2022-07-22T17:25:55.647017Z",
     "iopub.status.idle": "2022-07-22T17:25:55.658812Z",
     "shell.execute_reply": "2022-07-22T17:25:55.657978Z"
    },
    "papermill": {
     "duration": 0.027187,
     "end_time": "2022-07-22T17:25:55.660687",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.633500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_df(df, root_dir):\n",
    "    all_images = []\n",
    "    for path in Path(root_dir).rglob('*.png'):\n",
    "\n",
    "        parts = path.parts\n",
    "        dict_path = {}\n",
    "        case_str = parts[4][4:]\n",
    "        day_str = parts[5].split('_')[1][3:]\n",
    "        #dict_path['case'] = int(case_str)\n",
    "        #dict_path['day'] = int(day_str)\n",
    "        dict_path['slice'] = int(parts[7].split('_')[1])\n",
    "        slice_str = '_'.join(parts[7].split('_')[0:2])\n",
    "        #dict_path['PosixPath'] = path\n",
    "        dict_path['path'] = str(path)\n",
    "        dict_path['join_col'] = 'case'+ case_str + '_'+ 'day' + day_str + '_' + slice_str\n",
    "        dict_path['height'] = int(dict_path['path'].split('/')[7].split('_')[2])\n",
    "        dict_path['width'] = int(dict_path['path'].split('/')[7].split('_')[3])\n",
    "        dict_path['subject'] = case_str + '_'+ day_str\n",
    "        #dict_path['matching_str_inference'] = dict_path['subject'] + '_' +str(dict_path['slice'])\n",
    "        all_images.append(dict_path)\n",
    "    \n",
    "    # Only contains 1/3 length of the orginal df(where each slice is repeated 3 times )\n",
    "    df_1_3 = pd.DataFrame(all_images) \n",
    "    if df_1_3.empty:\n",
    "        df = pd.DataFrame(columns={'id','class','predicted','slice','path','height','width','subject'})\n",
    "        return df[['id','class','predicted','slice','path','height','width','subject']]\n",
    "    # Get the final dataframe with the same length of the original one...\n",
    "    else :\n",
    "        df_final = pd.merge(df, df_1_3, left_on = 'id', right_on = 'join_col')\n",
    "        df_final = df_final.drop('join_col', axis=1)\n",
    "        df_final[['path','subject']] = df_final[['path','subject']].astype(\"Sparse[str]\")\n",
    "        df_final[['height','width','slice']]=df_final[['height','width','slice']].astype('int16')\n",
    "        \n",
    "        #I have to deactivate these 3 rows:here it is just to mimic the test set (for debugging)\n",
    "        #df_final['segmentation'] =np.nan\n",
    "        #df_final = df_final[['id','class','segmentation','slice','path','height','width','subject']]\n",
    "        #df_final.columns = ['id','class','predicted','slice','path','height','width','subject']\n",
    "        \n",
    "        return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "570ba612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.686078Z",
     "iopub.status.busy": "2022-07-22T17:25:55.685340Z",
     "iopub.status.idle": "2022-07-22T17:25:55.700469Z",
     "shell.execute_reply": "2022-07-22T17:25:55.699655Z"
    },
    "papermill": {
     "duration": 0.029643,
     "end_time": "2022-07-22T17:25:55.702217",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.672574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = prepare_df(df_original, ROOT_DIR)\n",
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d3979ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.728819Z",
     "iopub.status.busy": "2022-07-22T17:25:55.728543Z",
     "iopub.status.idle": "2022-07-22T17:25:55.738547Z",
     "shell.execute_reply": "2022-07-22T17:25:55.737732Z"
    },
    "papermill": {
     "duration": 0.024792,
     "end_time": "2022-07-22T17:25:55.740448",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.715656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rearrange_df(df):\n",
    "    \"\"\" \n",
    "    Rearrange data in the the prepared DataFrame (train_df or test_df).\n",
    "    For each id (repeated 3 times),it creates 3 associated columns representing the segmentation \n",
    "    for the 3 classes:'large_bowel', 'small_bowel', 'stomach' \n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        df = pd.DataFrame(columns={'id','large_bowel','small_bowel','stomach','subject',\n",
    "                                  'slice','path','width','height'})\n",
    "        return df[['id','large_bowel','small_bowel','stomach','subject','slice','path','width','height']]\n",
    "    else:\n",
    "        # I keep only one id (so that it is not repeated 3 times)\n",
    "        df_rearranged = pd.DataFrame({\"id\": df[\"id\"][::3]}) \n",
    "        df_rearranged[\"large_bowel\"] = df[\"predicted\"][::3].values\n",
    "        df_rearranged[\"small_bowel\"] = df[\"predicted\"][1::3].values\n",
    "        df_rearranged[\"stomach\"] = df[\"predicted\"][2::3].values\n",
    "        # Adjust the corresponding other columns\n",
    "        #df_rearranged[\"case\"] = df[\"case\"][::3].values\n",
    "        #df_rearranged[\"day\"] = df[\"day\"][::3].values\n",
    "        df_rearranged[\"subject\"] = df[\"subject\"][::3].values\n",
    "        df_rearranged[\"slice\"] = df[\"slice\"][::3].values\n",
    "        df_rearranged[\"path\"] = df[\"path\"][::3].values\n",
    "        df_rearranged[\"width\"] = df[\"width\"][::3].values\n",
    "        df_rearranged[\"height\"] = df[\"height\"][::3].values\n",
    "        #df_rearranged[\"matching_str_inference\"] = df[\"matching_str_inference\"][::3].values\n",
    "        df_rearranged = df_rearranged.reset_index(drop=True)\n",
    "        df_rearranged = df_rearranged.fillna(\"\")\n",
    "        return df_rearranged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f2596c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.765906Z",
     "iopub.status.busy": "2022-07-22T17:25:55.765394Z",
     "iopub.status.idle": "2022-07-22T17:25:55.771845Z",
     "shell.execute_reply": "2022-07-22T17:25:55.771038Z"
    },
    "papermill": {
     "duration": 0.021351,
     "end_time": "2022-07-22T17:25:55.773844",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.752493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_rearranged = rearrange_df(df)\n",
    "#df_rearranged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b33cbc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.800094Z",
     "iopub.status.busy": "2022-07-22T17:25:55.799321Z",
     "iopub.status.idle": "2022-07-22T17:25:55.803343Z",
     "shell.execute_reply": "2022-07-22T17:25:55.802368Z"
    },
    "papermill": {
     "duration": 0.019329,
     "end_time": "2022-07-22T17:25:55.805475",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.786146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for debugging (from train set)\n",
    "#df_rearranged = df_rearranged[0:7200] # 50 cases as the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7c2f0e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.831169Z",
     "iopub.status.busy": "2022-07-22T17:25:55.830914Z",
     "iopub.status.idle": "2022-07-22T17:25:55.839113Z",
     "shell.execute_reply": "2022-07-22T17:25:55.838144Z"
    },
    "papermill": {
     "duration": 0.022925,
     "end_time": "2022-07-22T17:25:55.841172",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.818247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_list_subjects_slices(rearranged_df):\n",
    "    if rearranged_df.empty:\n",
    "        return [],[]\n",
    "    else: \n",
    "        list_subjects_dict = []\n",
    "        for subject, slices in list(rearranged_df.groupby('subject')['path']):\n",
    "            dict_subject ={}\n",
    "            list_slices_arrays = []\n",
    "            for path_slice in slices.values:\n",
    "                arr_img = cv2.imread(path_slice, cv2.IMREAD_ANYDEPTH)\n",
    "                resized_arr_image = cv2.resize(arr_img, (128,128), interpolation=cv2.INTER_NEAREST)\n",
    "                list_slices_arrays.append(resized_arr_image)\n",
    "            dict_subject[subject] = list_slices_arrays\n",
    "            list_subjects_dict.append(dict_subject)\n",
    "    \n",
    "        list_subjects_slices=[]\n",
    "        list_subjects = []\n",
    "        for x_dict in list_subjects_dict:\n",
    "            for key_subject in x_dict:\n",
    "                list_subjects_slices.append(x_dict[key_subject])\n",
    "                list_subjects.append(key_subject)\n",
    "        gc.collect()\n",
    "        del list_subjects_dict \n",
    "        return list_subjects_slices, list_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f54a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.865980Z",
     "iopub.status.busy": "2022-07-22T17:25:55.865730Z",
     "iopub.status.idle": "2022-07-22T17:25:55.869927Z",
     "shell.execute_reply": "2022-07-22T17:25:55.868960Z"
    },
    "papermill": {
     "duration": 0.018874,
     "end_time": "2022-07-22T17:25:55.871852",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.852978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_slices, list_subjects = create_list_subjects_slices(df_rearranged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6f451b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.897391Z",
     "iopub.status.busy": "2022-07-22T17:25:55.897122Z",
     "iopub.status.idle": "2022-07-22T17:25:55.904346Z",
     "shell.execute_reply": "2022-07-22T17:25:55.903422Z"
    },
    "papermill": {
     "duration": 0.022639,
     "end_time": "2022-07-22T17:25:55.906295",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.883656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create niftii MRI images \n",
    "def create_3d_mri_images(list_all_slices, list_subjects, root):\n",
    "    if (len(list_all_slices)==0)|(len(list_subjects)==0):\n",
    "        os.makedirs('./mri_images/')\n",
    "    else: \n",
    "        root_path = Path(root)\n",
    "        root_path.mkdir(parents=True, exist_ok=True)\n",
    "        list_mri_arrays=[]\n",
    "        for subject, slices_subject in zip(list_subjects,list_all_slices):\n",
    "            mri_subject = np.asarray(slices_subject)\n",
    "            mri_subject = np.swapaxes(mri_subject, 0, 2) # (num_slices,w,h) --> (h, w, num_slices)\n",
    "            mri_subject = np.swapaxes(mri_subject, 0, 1) # (h,w, num_slices) --> (w,h,num_slices)\n",
    "            mri_subject_nifti = nib.Nifti1Image(mri_subject, affine=np.eye(4))\n",
    "            nib.save(mri_subject_nifti, root+subject+'.nii.gz')\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "131f0abf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:55.932376Z",
     "iopub.status.busy": "2022-07-22T17:25:55.931661Z",
     "iopub.status.idle": "2022-07-22T17:25:56.226419Z",
     "shell.execute_reply": "2022-07-22T17:25:56.225368Z"
    },
    "papermill": {
     "duration": 0.310531,
     "end_time": "2022-07-22T17:25:56.229288",
     "exception": false,
     "start_time": "2022-07-22T17:25:55.918757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_3d_mri_images(list_slices,list_subjects, root= './mri_images/')\n",
    "\n",
    "del list_slices[:]\n",
    "del list_slices\n",
    "del list_subjects[:]\n",
    "del list_subjects\n",
    "gc.collect()\n",
    "gc.collect(generation=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad883cc7",
   "metadata": {
    "papermill": {
     "duration": 0.014531,
     "end_time": "2022-07-22T17:25:56.256833",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.242302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Dataset & Model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99fc55dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.283016Z",
     "iopub.status.busy": "2022-07-22T17:25:56.282683Z",
     "iopub.status.idle": "2022-07-22T17:25:56.288852Z",
     "shell.execute_reply": "2022-07-22T17:25:56.287854Z"
    },
    "papermill": {
     "duration": 0.02153,
     "end_time": "2022-07-22T17:25:56.290898",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.269368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_test = Path('./mri_images')\n",
    "\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    subjects_test_paths = sorted(list(path_test.glob(\"*nii.gz\")))\n",
    "    subjects_test = []\n",
    "\n",
    "    for subject_path in subjects_test_paths:\n",
    "        subject = tio.Subject({\"MRI\":tio.ScalarImage(subject_path)})\n",
    "        subjects_test.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04063660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.317526Z",
     "iopub.status.busy": "2022-07-22T17:25:56.317230Z",
     "iopub.status.idle": "2022-07-22T17:25:56.324366Z",
     "shell.execute_reply": "2022-07-22T17:25:56.323495Z"
    },
    "papermill": {
     "duration": 0.023094,
     "end_time": "2022-07-22T17:25:56.326469",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.303375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I will need it because I'll use CropOrPad to (128,128,144)\n",
    "# But I need the real number of slices, mainly for the padded slices (during running inference code...)\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    list_size = []\n",
    "    for element in subjects_test:\n",
    "        list_size.append(element['MRI']['data'].shape[3])\n",
    "    list_size_scans = np.array(list_size).astype(np.int16)\n",
    "    del list_size\n",
    "    list_size_scans = list(list_size_scans)\n",
    "    #np.unique(list_size_scans,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48976cb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.352070Z",
     "iopub.status.busy": "2022-07-22T17:25:56.351721Z",
     "iopub.status.idle": "2022-07-22T17:25:56.357231Z",
     "shell.execute_reply": "2022-07-22T17:25:56.356273Z"
    },
    "papermill": {
     "duration": 0.020586,
     "end_time": "2022-07-22T17:25:56.359288",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.338702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Histogram Standardization\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    histogram_landmarks_path = './landmarks.npy' # juste path \n",
    "\n",
    "    landmarks = tio.HistogramStandardization.train(\n",
    "        subjects_test_paths,\n",
    "        output_path=histogram_landmarks_path,)\n",
    "    np.set_printoptions(suppress=True, precision=3)\n",
    "    print('\\nTrained landmarks:', landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b802ab30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.385921Z",
     "iopub.status.busy": "2022-07-22T17:25:56.385183Z",
     "iopub.status.idle": "2022-07-22T17:25:56.390906Z",
     "shell.execute_reply": "2022-07-22T17:25:56.390084Z"
    },
    "papermill": {
     "duration": 0.020731,
     "end_time": "2022-07-22T17:25:56.392848",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.372117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    process = tio.Compose([\n",
    "        tio.CropOrPad((128,128, 144)),\n",
    "        tio.HistogramStandardization({'MRI': landmarks}),\n",
    "        tio.ZNormalization(masking_method=tio.ZNormalization.mean)])\n",
    "    test_transform = process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef927c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.418685Z",
     "iopub.status.busy": "2022-07-22T17:25:56.417929Z",
     "iopub.status.idle": "2022-07-22T17:25:56.422918Z",
     "shell.execute_reply": "2022-07-22T17:25:56.422070Z"
    },
    "papermill": {
     "duration": 0.019828,
     "end_time": "2022-07-22T17:25:56.424955",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.405127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the TorchIo Test Dataset\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    test_dataset = tio.SubjectsDataset(subjects_test, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd7f1087",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.454698Z",
     "iopub.status.busy": "2022-07-22T17:25:56.450421Z",
     "iopub.status.idle": "2022-07-22T17:25:56.467345Z",
     "shell.execute_reply": "2022-07-22T17:25:56.466523Z"
    },
    "papermill": {
     "duration": 0.032036,
     "end_time": "2022-07-22T17:25:56.469549",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.437513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SegmentMadisonOrgans(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = HighRes3DNet(in_channels=1, out_channels=4)\n",
    "        self.loss_fn = DiceLoss(mode ='multiclass',classes=4, from_logits=True)\n",
    "         \n",
    "        self.metric = torchmetrics.JaccardIndex(num_classes=4)\n",
    "        self.lr = 5e-4\n",
    "    \n",
    "    def forward(self, data):\n",
    "        pred = self.model(data)\n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img = batch[\"MRI\"][\"data\"] # in TorhIo, we need to acess the label entry \"MRI\", then \"data\"\n",
    "        mask = batch[\"Label\"][\"data\"][:,0]  # Remove single channel as Loss expects NxHxW\n",
    "        mask = mask.long()\n",
    "        \n",
    "        pred = self(img)\n",
    "        loss = self.loss_fn(pred, mask)\n",
    "        iou = self.metric(pred,mask)\n",
    "        self.log(\"Train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('Train_iou',iou, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img = batch[\"MRI\"][\"data\"]\n",
    "        mask = batch[\"Label\"][\"data\"][:,0]  # Remove single channel --> NxHxW\n",
    "        mask = mask.long()\n",
    "        \n",
    "        pred = self(img)\n",
    "        loss = self.loss_fn(pred, mask)\n",
    "        iou = self.metric(pred,mask)\n",
    "        self.log(\"Val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('Val_iou',iou, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt=torch.optim.AdamW(self.parameters(),lr=self.lr)\n",
    "        scheduler= torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=3,verbose=True)\n",
    "        return {'optimizer':opt,'scheduler':scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70c6afd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.496771Z",
     "iopub.status.busy": "2022-07-22T17:25:56.495254Z",
     "iopub.status.idle": "2022-07-22T17:25:56.501585Z",
     "shell.execute_reply": "2022-07-22T17:25:56.500627Z"
    },
    "papermill": {
     "duration": 0.021786,
     "end_time": "2022-07-22T17:25:56.503553",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.481767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    model = SegmentMadisonOrgans.load_from_checkpoint('../input/weights-128-3d/epoch40-step6970.ckpt')\n",
    "    model = model.eval()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc289c6",
   "metadata": {
    "papermill": {
     "duration": 0.012112,
     "end_time": "2022-07-22T17:25:56.528234",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.516122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Predictions** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e945b782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.554482Z",
     "iopub.status.busy": "2022-07-22T17:25:56.553637Z",
     "iopub.status.idle": "2022-07-22T17:25:56.564549Z",
     "shell.execute_reply": "2022-07-22T17:25:56.563619Z"
    },
    "papermill": {
     "duration": 0.026178,
     "end_time": "2022-07-22T17:25:56.566608",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.540430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predictions without TTA: Test Time Augmentation\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    all_preds =[]\n",
    "    for idx in tqdm(range(0,len(test_dataset))):\n",
    "        imgs = test_dataset[idx][\"MRI\"][\"data\"]\n",
    "        grid_sampler = tio.inference.GridSampler(test_dataset[idx], 96, (8, 8, 8))\n",
    "        aggregator = tio.inference.GridAggregator(grid_sampler)\n",
    "        patch_loader = torch.utils.data.DataLoader(grid_sampler, batch_size=4)\n",
    "        with torch.no_grad():\n",
    "            for patches_batch in patch_loader:\n",
    "                input_tensor = patches_batch['MRI'][\"data\"].to(device)  # Get batch of patches\n",
    "                locations = patches_batch[tio.LOCATION]  # Get locations of patches\n",
    "                pred = model(input_tensor)  # Compute prediction\n",
    "                aggregator.add_batch(pred, locations)  # Combine predictions to volume\n",
    "            output_tensor = aggregator.get_output_tensor()\n",
    "            del aggregator\n",
    "            gc.collect()\n",
    "            pred = output_tensor.argmax(0)\n",
    "            del output_tensor\n",
    "            gc.collect()\n",
    "            if (list_size_scans[idx] != 144):\n",
    "                size = list_size_scans[idx]\n",
    "                pred = pred[:,:,int((144-size)/2): -int((144-size)/2)]\n",
    "            all_preds.append(pred.to(torch.int8))\n",
    "            del pred\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ddafa4",
   "metadata": {
    "papermill": {
     "duration": 0.012087,
     "end_time": "2022-07-22T17:25:56.590671",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.578584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **TTA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f02c98b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.617198Z",
     "iopub.status.busy": "2022-07-22T17:25:56.616911Z",
     "iopub.status.idle": "2022-07-22T17:25:56.629164Z",
     "shell.execute_reply": "2022-07-22T17:25:56.628104Z"
    },
    "papermill": {
     "duration": 0.028722,
     "end_time": "2022-07-22T17:25:56.631639",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.602917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    num_augmentations = 4\n",
    "\n",
    "    #flip_lateral = tio.RandomFlip(flip_probability=1)\n",
    "    #flip_Right = tio.RandomFlip(axes=['Right'], flip_probability=0.8)\n",
    "\n",
    "    augment = tio.RandomFlip(flip_probability=1)\n",
    "\n",
    "    all_preds_aug =[]\n",
    "    for idx in tqdm(range(0,len(test_dataset))):\n",
    "        results = []\n",
    "        for _ in range(num_augmentations):\n",
    "            augmented = augment(test_dataset[idx])\n",
    "            grid_sampler = tio.inference.GridSampler(augmented, 96, (8, 8, 8))\n",
    "            aggregator = tio.inference.GridAggregator(grid_sampler)\n",
    "            patch_loader = torch.utils.data.DataLoader(grid_sampler, batch_size=4)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for patches_batch in patch_loader:\n",
    "                input_tensor = patches_batch['MRI'][\"data\"].to(device)  # Get batch of patches\n",
    "                locations = patches_batch[tio.LOCATION]  # Get locations of patches\n",
    "                pred = model(input_tensor)  # Compute prediction\n",
    "                aggregator.add_batch(pred, locations)  # Combine predictions to volume\n",
    "            output_tensor = aggregator.get_output_tensor()\n",
    "            del aggregator\n",
    "            gc.collect()\n",
    "            pred = output_tensor.argmax(0)\n",
    "            del output_tensor\n",
    "            gc.collect()\n",
    "            # I add the label to tioSubject(using the MRI image data)\n",
    "            # NB: augmented.MRI.affine access the original shape of MRI, not the padded or corpped\n",
    "            # So: no need to loop over scans shape... like it was with simple predictions above\n",
    "            lm_temp = tio.LabelMap(tensor=torch.rand(1,1,1,1), affine=augmented.MRI.affine)\n",
    "            augmented.add_image(lm_temp, 'Label')\n",
    "            augmented.Label.set_data(torch.unsqueeze(pred,dim=0))# TorchIo Subject has BS dim\n",
    "            back = augmented.apply_inverse_transform(warn=True)\n",
    "            results.append(back.Label.data[0]) # to get rid of BS dimension\n",
    "        results.append(all_preds[idx])\n",
    "        result = torch.stack(results).long()\n",
    "        tta_result_tensor = result.mode(dim=0).values\n",
    "        \n",
    "        # Here we don't need this because MRI.affine access the original size (see above)\n",
    "        #if (list_size_scans[idx] != 144):\n",
    "            #size = list_size_scans[idx]\n",
    "            #tta_result_tensor= tta_result_tensor[:,:,int((144-size)/2): -int((144-size)/2)]\n",
    "        all_preds_aug.append(tta_result_tensor.to(torch.int8))\n",
    "        del tta_result_tensor\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b50bc137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.659447Z",
     "iopub.status.busy": "2022-07-22T17:25:56.657913Z",
     "iopub.status.idle": "2022-07-22T17:25:56.663382Z",
     "shell.execute_reply": "2022-07-22T17:25:56.662541Z"
    },
    "papermill": {
     "duration": 0.020914,
     "end_time": "2022-07-22T17:25:56.665326",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.644412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Becasue of TTA\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    del all_preds\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeefd2e",
   "metadata": {
    "papermill": {
     "duration": 0.01462,
     "end_time": "2022-07-22T17:25:56.692316",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.677696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Rearrange Predictions for submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff91d9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.719317Z",
     "iopub.status.busy": "2022-07-22T17:25:56.719025Z",
     "iopub.status.idle": "2022-07-22T17:25:56.724427Z",
     "shell.execute_reply": "2022-07-22T17:25:56.723439Z"
    },
    "papermill": {
     "duration": 0.021985,
     "end_time": "2022-07-22T17:25:56.726664",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.704679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list paths of transformed niftii test images (/output)\n",
    "# we got it (the sorted list before creating the TorchIo Dataset)\n",
    "# subjects_test_paths\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    list_cases = [element.parts[1][:-7] for element in subjects_test_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d80935f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.754212Z",
     "iopub.status.busy": "2022-07-22T17:25:56.753386Z",
     "iopub.status.idle": "2022-07-22T17:25:56.759848Z",
     "shell.execute_reply": "2022-07-22T17:25:56.758743Z"
    },
    "papermill": {
     "duration": 0.022943,
     "end_time": "2022-07-22T17:25:56.762126",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.739183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a dictionary that associates each case to its 3D mask (128,128,144) or (128,128,80)\n",
    "# Still with the resized masks\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    dict_cases_preds = {}\n",
    "\n",
    "    #cases and all_preds or (all_preds_aug if TTA) are in the same order since test_dataset was created from the sorted list..\n",
    "    for case,pred in zip(list_cases, all_preds_aug):\n",
    "        dict_cases_preds[case] = [pred[:,:,i].numpy() for i in range(0,pred.shape[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f85b031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.791793Z",
     "iopub.status.busy": "2022-07-22T17:25:56.791073Z",
     "iopub.status.idle": "2022-07-22T17:25:56.797595Z",
     "shell.execute_reply": "2022-07-22T17:25:56.796585Z"
    },
    "papermill": {
     "duration": 0.02388,
     "end_time": "2022-07-22T17:25:56.800004",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.776124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_reconst= pd.DataFrame(columns={'case', 'pred','slice'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bc8480e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.828060Z",
     "iopub.status.busy": "2022-07-22T17:25:56.827204Z",
     "iopub.status.idle": "2022-07-22T17:25:56.833079Z",
     "shell.execute_reply": "2022-07-22T17:25:56.832118Z"
    },
    "papermill": {
     "duration": 0.021812,
     "end_time": "2022-07-22T17:25:56.835058",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.813246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the case column from test cases (first from 3D scans not from .csv)\n",
    "# I'll restore 2D slices form 3D masks\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    column_case = []\n",
    "    for case in list(dict_cases_preds.keys()):\n",
    "        column_case += [case]*len(dict_cases_preds[case])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0499a01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.861504Z",
     "iopub.status.busy": "2022-07-22T17:25:56.860782Z",
     "iopub.status.idle": "2022-07-22T17:25:56.866266Z",
     "shell.execute_reply": "2022-07-22T17:25:56.865422Z"
    },
    "papermill": {
     "duration": 0.020601,
     "end_time": "2022-07-22T17:25:56.868158",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.847557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the predictions column (extract 2D predictions form 3D predictions)\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    preds_col = []\n",
    "    for preds_case in list(dict_cases_preds.values()):\n",
    "        preds_col += preds_case\n",
    "#print(len(preds_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "759dfdfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.893921Z",
     "iopub.status.busy": "2022-07-22T17:25:56.893667Z",
     "iopub.status.idle": "2022-07-22T17:25:56.898416Z",
     "shell.execute_reply": "2022-07-22T17:25:56.897468Z"
    },
    "papermill": {
     "duration": 0.01963,
     "end_time": "2022-07-22T17:25:56.900428",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.880798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    df_reconst['case'] = column_case\n",
    "    df_reconst['pred'] = preds_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e75e4b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.925634Z",
     "iopub.status.busy": "2022-07-22T17:25:56.925333Z",
     "iopub.status.idle": "2022-07-22T17:25:56.931763Z",
     "shell.execute_reply": "2022-07-22T17:25:56.930793Z"
    },
    "papermill": {
     "duration": 0.0213,
     "end_time": "2022-07-22T17:25:56.933650",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.912350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the large_bowel, small_bowel & stomach predictions\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    df_reconst['large_bowel'] = df_reconst.apply(lambda x: (x['pred']==1).astype('int8'), axis=1)\n",
    "    df_reconst['small_bowel'] = df_reconst.apply(lambda x: (x['pred']==2).astype('int8'), axis=1)\n",
    "    df_reconst['stomach'] = df_reconst.apply(lambda x: (x['pred']==3).astype('int8'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6352fd59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.960059Z",
     "iopub.status.busy": "2022-07-22T17:25:56.959450Z",
     "iopub.status.idle": "2022-07-22T17:25:56.965429Z",
     "shell.execute_reply": "2022-07-22T17:25:56.964507Z"
    },
    "papermill": {
     "duration": 0.021407,
     "end_time": "2022-07-22T17:25:56.967498",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.946091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# restore the form of the submission file. For each slice I have 3 rows (one for large_bowel\n",
    "# one row for small_bowle and one row for stomach)\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    list_case = list(df_reconst['case'])\n",
    "    list_subject_mult3 =[]\n",
    "    for element in list_case:\n",
    "        list_subject_mult3 += [element]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a45f57d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:56.995003Z",
     "iopub.status.busy": "2022-07-22T17:25:56.993375Z",
     "iopub.status.idle": "2022-07-22T17:25:56.999379Z",
     "shell.execute_reply": "2022-07-22T17:25:56.998405Z"
    },
    "papermill": {
     "duration": 0.021608,
     "end_time": "2022-07-22T17:25:57.001431",
     "exception": false,
     "start_time": "2022-07-22T17:25:56.979823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    df_final = pd.DataFrame(columns={'class','segmentation','subject','slice','width', 'height'})\n",
    "    df_final['subject'] = list_subject_mult3\n",
    "#len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ca3f2c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.027683Z",
     "iopub.status.busy": "2022-07-22T17:25:57.026892Z",
     "iopub.status.idle": "2022-07-22T17:25:57.032560Z",
     "shell.execute_reply": "2022-07-22T17:25:57.031726Z"
    },
    "papermill": {
     "duration": 0.021273,
     "end_time": "2022-07-22T17:25:57.034723",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.013450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Segmentation column\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    df_final['segmentation'][::3] = df_reconst['large_bowel']\n",
    "    df_final['segmentation'][1::3] = df_reconst['small_bowel']\n",
    "    df_final['segmentation'][2::3] = df_reconst['stomach']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6816aba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.061408Z",
     "iopub.status.busy": "2022-07-22T17:25:57.061153Z",
     "iopub.status.idle": "2022-07-22T17:25:57.066815Z",
     "shell.execute_reply": "2022-07-22T17:25:57.065768Z"
    },
    "papermill": {
     "duration": 0.021252,
     "end_time": "2022-07-22T17:25:57.068802",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.047550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class column as submission file\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    df_final['class'][::3] = ['large_bowel']*len(df_reconst)\n",
    "    df_final['class'][1::3] = ['small_bowel']*len(df_reconst)\n",
    "    df_final['class'][2::3] = ['stomach']*len(df_reconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13a441c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.096066Z",
     "iopub.status.busy": "2022-07-22T17:25:57.095263Z",
     "iopub.status.idle": "2022-07-22T17:25:57.101757Z",
     "shell.execute_reply": "2022-07-22T17:25:57.101004Z"
    },
    "papermill": {
     "duration": 0.022665,
     "end_time": "2022-07-22T17:25:57.103926",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.081261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract slice number from submission file (because we have no idea if the slices are in order\n",
    "# for example when we have 80 slices: they may be, 1,2,4,8,10 and not 1,2,3,4,5...)\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    list_subject_slices= list(df_rearranged.groupby('subject')['slice']) # liste des tuples ('suject','series of slices')\n",
    "\n",
    "    list_dict_subject_slices=[]\n",
    "    for subject, series_slices in list_subject_slices:\n",
    "        dict_subject_slices ={}\n",
    "        dict_subject_slices[subject] = list(series_slices.values)\n",
    "        list_dict_subject_slices.append(dict_subject_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b2d9094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.132872Z",
     "iopub.status.busy": "2022-07-22T17:25:57.132013Z",
     "iopub.status.idle": "2022-07-22T17:25:57.139753Z",
     "shell.execute_reply": "2022-07-22T17:25:57.138799Z"
    },
    "papermill": {
     "duration": 0.024413,
     "end_time": "2022-07-22T17:25:57.141869",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.117456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Activate this for inference competition test set\n",
    "\n",
    "# slice column\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    for element in list_dict_subject_slices:\n",
    "        list_slices_mult3=[]\n",
    "        for el in list(element.values())[0]: # loop over slices of a subject\n",
    "            list_slices_mult3 += [el]*3 # because 3rows for each slice: large_bowel, small and stomach\n",
    "            # list(element.keys())[0] is an elment for example '101_20'\n",
    "            # and list(element.values())[0] is for example [1,2,3,.....,144]\n",
    "        if len(df_final['slice'].loc[df_final.subject==list(element.keys())[0]])!= len(list_slices_mult3):\n",
    "            print(element.keys())\n",
    "        df_final['slice'].loc[df_final.subject==list(element.keys())[0]]= list_slices_mult3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba8ab56c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.169965Z",
     "iopub.status.busy": "2022-07-22T17:25:57.169673Z",
     "iopub.status.idle": "2022-07-22T17:25:57.175472Z",
     "shell.execute_reply": "2022-07-22T17:25:57.174380Z"
    },
    "papermill": {
     "duration": 0.022045,
     "end_time": "2022-07-22T17:25:57.177436",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.155391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# id column\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    df_final['id']= df_final.apply(lambda x: 'case'+x['subject'].split('_')[0]+'_day'+x['subject'].split('_')[1]+'_slice_'+str(x['slice']).zfill(4),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f70178be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.203663Z",
     "iopub.status.busy": "2022-07-22T17:25:57.202868Z",
     "iopub.status.idle": "2022-07-22T17:25:57.210414Z",
     "shell.execute_reply": "2022-07-22T17:25:57.209619Z"
    },
    "papermill": {
     "duration": 0.022826,
     "end_time": "2022-07-22T17:25:57.212342",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.189516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    # width column (for inference)\n",
    "    list_subject_width= list(df_rearranged.groupby('subject')['width']) \n",
    "    list_dict_subject_widths=[]\n",
    "    for subject, series_widths in list_subject_width:\n",
    "        dict_subject_width ={}\n",
    "        dict_subject_width[subject] = list(series_widths.values)\n",
    "        list_dict_subject_widths.append(dict_subject_width)\n",
    "\n",
    "\n",
    "    for element in list_dict_subject_widths:\n",
    "        list_width_mult3=[]\n",
    "        for el in list(element.values())[0]:\n",
    "            list_width_mult3 += [el]*3\n",
    "        df_final['width'].loc[df_final.subject==list(element.keys())[0]]= list_width_mult3\n",
    "    del list_dict_subject_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfd8b67f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.238407Z",
     "iopub.status.busy": "2022-07-22T17:25:57.237692Z",
     "iopub.status.idle": "2022-07-22T17:25:57.245211Z",
     "shell.execute_reply": "2022-07-22T17:25:57.244225Z"
    },
    "papermill": {
     "duration": 0.022605,
     "end_time": "2022-07-22T17:25:57.247284",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.224679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# height column for inference\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    list_subject_height= list(df_rearranged.groupby('subject')['height']) # list of tuples ('suject','series of slices')\n",
    "    list_dict_subject_heights=[]\n",
    "    for subject, series_heights in list_subject_height:\n",
    "        dict_subject_height ={}\n",
    "        dict_subject_height[subject] = list(series_heights .values)\n",
    "        list_dict_subject_heights.append(dict_subject_height)\n",
    "\n",
    "    for element in list_dict_subject_heights:\n",
    "        list_height_mult3=[]\n",
    "        for el in list(element.values())[0]:\n",
    "            list_height_mult3 += [el]*3\n",
    "        df_final['height'].loc[df_final.subject==list(element.keys())[0]]= list_height_mult3\n",
    "    del list_dict_subject_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eeb1d8ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.272777Z",
     "iopub.status.busy": "2022-07-22T17:25:57.271909Z",
     "iopub.status.idle": "2022-07-22T17:25:57.276230Z",
     "shell.execute_reply": "2022-07-22T17:25:57.275384Z"
    },
    "papermill": {
     "duration": 0.019027,
     "end_time": "2022-07-22T17:25:57.278144",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.259117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e61e63a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.303455Z",
     "iopub.status.busy": "2022-07-22T17:25:57.302749Z",
     "iopub.status.idle": "2022-07-22T17:25:57.308251Z",
     "shell.execute_reply": "2022-07-22T17:25:57.307425Z"
    },
    "papermill": {
     "duration": 0.020274,
     "end_time": "2022-07-22T17:25:57.310329",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.290055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add resized segmentation (to the original size)\n",
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    df_final['segment_resized'] = df_final.apply(lambda x: cv2.resize(x['segmentation'], (x['width'], x['height']),interpolation=cv2.INTER_NEAREST), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18481d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.336195Z",
     "iopub.status.busy": "2022-07-22T17:25:57.335367Z",
     "iopub.status.idle": "2022-07-22T17:25:57.341963Z",
     "shell.execute_reply": "2022-07-22T17:25:57.341133Z"
    },
    "papermill": {
     "duration": 0.021642,
     "end_time": "2022-07-22T17:25:57.343958",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.322316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rle Encoding\n",
    "\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.flatten() # était img.T.flatten() (car height and width reversed)\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88f7bc7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.369954Z",
     "iopub.status.busy": "2022-07-22T17:25:57.369112Z",
     "iopub.status.idle": "2022-07-22T17:25:57.374980Z",
     "shell.execute_reply": "2022-07-22T17:25:57.374121Z"
    },
    "papermill": {
     "duration": 0.020739,
     "end_time": "2022-07-22T17:25:57.376915",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.356176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    df_final['predicted'] = df_final.apply(lambda x:mask2rle(x['segment_resized']), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22cbaab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.402210Z",
     "iopub.status.busy": "2022-07-22T17:25:57.401410Z",
     "iopub.status.idle": "2022-07-22T17:25:57.406600Z",
     "shell.execute_reply": "2022-07-22T17:25:57.405776Z"
    },
    "papermill": {
     "duration": 0.019664,
     "end_time": "2022-07-22T17:25:57.408459",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.388795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.listdir(path_test):\n",
    "    pass\n",
    "else: \n",
    "    df_final.drop(['height','width','subject','segmentation','segment_resized','slice'], axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e987a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:57.433839Z",
     "iopub.status.busy": "2022-07-22T17:25:57.433113Z",
     "iopub.status.idle": "2022-07-22T17:25:58.041264Z",
     "shell.execute_reply": "2022-07-22T17:25:58.040261Z"
    },
    "papermill": {
     "duration": 0.623423,
     "end_time": "2022-07-22T17:25:58.043861",
     "exception": false,
     "start_time": "2022-07-22T17:25:57.420438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.listdir(path_test):\n",
    "    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\n",
    "    sub_df.columns = ['id','class','predicted']\n",
    "else: \n",
    "    sub_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n",
    "    sub_df.drop(['predicted'], axis=1, inplace=True)\n",
    "    sub_df = sub_df.merge(df_final, on=['id','class'])\n",
    "    sub_df =sub_df[['id','class','predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3c1cdf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T17:25:58.070557Z",
     "iopub.status.busy": "2022-07-22T17:25:58.070268Z",
     "iopub.status.idle": "2022-07-22T17:25:59.102497Z",
     "shell.execute_reply": "2022-07-22T17:25:59.101564Z"
    },
    "papermill": {
     "duration": 1.048268,
     "end_time": "2022-07-22T17:25:59.105430",
     "exception": false,
     "start_time": "2022-07-22T17:25:58.057162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case123_day20_slice_0001</td>\n",
       "      <td>stomach</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>large_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case123_day20_slice_0002</td>\n",
       "      <td>small_bowel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id        class predicted\n",
       "0  case123_day20_slice_0001  large_bowel       NaN\n",
       "1  case123_day20_slice_0001  small_bowel       NaN\n",
       "2  case123_day20_slice_0001      stomach       NaN\n",
       "3  case123_day20_slice_0002  large_bowel       NaN\n",
       "4  case123_day20_slice_0002  small_bowel       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_df.to_csv('submission.csv',index=False)\n",
    "display(sub_df.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 178.112768,
   "end_time": "2022-07-22T17:26:00.440913",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-22T17:23:02.328145",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
